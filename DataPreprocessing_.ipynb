{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fg4W-oF0QW6W",
        "outputId": "745393fd-0ff4-4151-a2c7-3827089ade87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Month  #Passengers\n",
            "0  1949-01          112\n",
            "1  1949-02          118\n",
            "2  1949-03          132\n",
            "3  1949-04          129\n",
            "4  1949-05          121\n",
            "   num__#Passengers remainder__Month\n",
            "0         -1.407779          1949-01\n",
            "1         -1.357590          1949-02\n",
            "2         -1.240483          1949-03\n",
            "3         -1.265578          1949-04\n",
            "4         -1.332496          1949-05\n",
            "    remainder__Month\n",
            "124          1959-05\n",
            "31           1951-08\n",
            "98           1957-03\n",
            "36           1952-01\n",
            "16           1950-05\n",
            "124    1.168570\n",
            "31    -0.680044\n",
            "98     0.633225\n",
            "36    -0.914258\n",
            "16    -1.299037\n",
            "Name: num__#Passengers, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('AirPassengers.csv', encoding=\"latin1\")\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())\n",
        "\n",
        "# 1. Data Cleaning\n",
        "# Updated num_features to include only available numeric columns\n",
        "num_features = ['#Passengers'] # Only '#Passengers' is a numeric feature\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# No categorical features available in this dataset based on the column list\n",
        "cat_features = []\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "# Combine preprocessing steps of Input Data\n",
        "# Only include the numerical transformer as there are no categorical features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", num_transformer, num_features),\n",
        "        # Removed categorical transformer as there are no categorical features\n",
        "        # (\"cat\", cat_transformer, cat_features)\n",
        "    ],\n",
        "    remainder='passthrough' # Keep other columns (like 'Month')\n",
        ")\n",
        "preprocessor.set_output(transform=\"pandas\")\n",
        "\n",
        "# Apply the transformations to the Input data\n",
        "data_preprocessed = preprocessor.fit_transform(data)\n",
        "\n",
        "# Generate more readable column names - this might need adjustment if column names are complex after preprocessing\n",
        "# For this simple case with only numerical features and passthrough, original names might be kept or slightly modified\n",
        "# Let's inspect the columns after preprocessing to decide on renaming\n",
        "print(data_preprocessed.head())\n",
        "\n",
        "\n",
        "# 3. Data Splitting\n",
        "# Assuming '#Passengers' is the target variable for this dataset based on the column list\n",
        "X = data_preprocessed.drop(columns=['num__#Passengers']) # Drop the scaled target variable\n",
        "y = data_preprocessed['num__#Passengers'] # Use the scaled target variable\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the first few rows\n",
        "print(X_train.head())\n",
        "print(y_train.head())"
      ]
    }
  ]
}